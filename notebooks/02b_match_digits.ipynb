{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Hands-on #2b: Matching digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We now turn to the second task and build a model that\n",
    "- receives two images of hand-written digits as input and\n",
    "- outputs a probability that both images show the same digit:\n",
    "\n",
    "![](img/match_digits.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('svg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Step 1: Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We use the MNIST dataset again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tdfs\n",
    "\n",
    "tdfs.disable_progress_bar()\n",
    "\n",
    "mnist_train = tdfs.load(name='mnist', split='train')\n",
    "mnist_test = tdfs.load(name='mnist', split='test')\n",
    "\n",
    "mnist_train, mnist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We now take pairs of subsequent samples, scale the images as before, and check whether the labels coincide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mnist_train.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def match_pairs(samples):\n",
    "    images, digits = samples['image'], samples['label']\n",
    "    matching = 1. if digits[0] == digits[1] else 0.\n",
    "    return (images[0] / 255, images[1]/255), matching\n",
    "\n",
    "\n",
    "Xy_train = mnist_train.batch(2).map(match_pairs)\n",
    "Xy_test = mnist_test.batch(2).map(match_pairs)\n",
    "\n",
    "Xy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let us see how many matching samples we have in our training set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Xy_train.reduce(tf.constant((0,0)), lambda count, sample: count + (sample[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Step 2: Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The `Sequential` class allows us to conveniently construct a neural network by stacking layers.\n",
    "\n",
    "But if we need more flexibility, for example, to construct\n",
    "\n",
    "- a model with multiple inputs or multiple outputs, or\n",
    "- a general directed acyclic graph of layers,\n",
    "\n",
    "we need to use the `tf.keras.Model` class, also known as the functional API of keras.\n",
    "\n",
    "The idea for our model is that we\n",
    "\n",
    "1. apply our pre-trained digit-classifier to both images,\n",
    "2. obtain two probability distributions $p^{(1)}$ and $p^{(2)}$,\n",
    "3. and use a dense layer to deduce the desired probability:\n",
    "\n",
    "![](img/digits_matcher.svg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "CLASSIFIFER_PATH = 'classifier'\n",
    "\n",
    "classifier = tf.keras.models.load_model(CLASSIFIFER_PATH)\n",
    "classifier.trainable = False\n",
    "\n",
    "def build_matcher_dense():\n",
    "    image_1 = tf.keras.layers.Input((28,28,1))\n",
    "    image_2 = tf.keras.layers.Input((28,28,1))\n",
    "    probs_1 = classifier(image_1)\n",
    "    probs_2 = classifier(image_2)\n",
    "    both_probs = tf.keras.layers.Concatenate()([probs_1, probs_2])\n",
    "    dense = tf.keras.layers.Dense(32, activation='relu')(both_probs)\n",
    "    prediction = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "    matcher = tf.keras.Model(inputs=[image_1, image_2], outputs=[prediction])\n",
    "    return matcher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's train our matcher!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, nr_batches=400, nr_epochs=5):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(Xy_train.repeat().batch(32).take(nr_batches),\n",
    "                        validation_data=Xy_test.repeat().batch(32).take(nr_batches // 2),\n",
    "                        epochs=nr_epochs)\n",
    "\n",
    "matcher = build_matcher_dense()\n",
    "train(matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let us now evaluate the matcher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate(model, nr_samples=1000):\n",
    "    y_true = np.stack(list(Xy_test.map(lambda _, p: p).take(nr_samples)))\n",
    "    y_pred = np.round(np.concatenate(model.predict(Xy_test.batch(nr_samples).take(1))))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "evaluate(matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Step 3: Building a  model that need not learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We now replace the last dense classification layer with a lambda layer that need not be trained, using the following observation:\n",
    "\n",
    "Given the two probability distributions $p^{(1)}$ and $p^{(2)}$, the probability that both digits coincide is $\\sum_i p^{(1)}_i p^{(2)}_i$.\n",
    "\n",
    "We can implement the formula in 3. using a `Lambda` layer. The catch is that all\n",
    "tensors flowing through the neural network are *batches* of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p1_batch = tf.constant([[0.1, 0.9], [0.5, 0.5]])\n",
    "p2_batch = tf.constant([[0.2, 0.8],  [0.4, 0.6]])\n",
    "\n",
    "def compute_prob_equality(p1_batch, p2_batch):\n",
    "    return tf.reduce_sum(p1_batch * p2_batch, axis=-1)\n",
    "\n",
    "\n",
    "compute_prob_equality(p1_batch, p2_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def build_matcher_lambda():\n",
    "    image_1 = tf.keras.layers.Input((28,28,1))\n",
    "    image_2 = tf.keras.layers.Input((28,28,1))\n",
    "    probs_1 = classifier(image_1)\n",
    "    probs_2 = classifier(image_2)\n",
    "    # both_probs = tf.keras.layers.Concatenate()([probs_1, probs_2])\n",
    "    prediction = tf.keras.layers.Lambda(lambda p: tf.reduce_sum(p[0] * p[1], axis=-1, keepdims=True))([probs_1, probs_2])\n",
    "    matcher = tf.keras.Model(inputs=[image_1, image_2], outputs=[prediction])\n",
    "    return matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's see how this model performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "matcher = build_matcher_lambda()\n",
    "evaluate(matcher)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This is quite good, isn't it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "02b_match_digits.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
